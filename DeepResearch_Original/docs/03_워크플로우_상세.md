# 워크플로우 상세 분석

## Phase 1: 사용자 명확화 (clarify_with_user)

### 목적
사용자 요청이 모호한 경우 추가 정보를 요청하여 연구 범위를 명확히 합니다.

### 구현

```python
async def clarify_with_user(state: AgentState, config: RunnableConfig) -> Command:
    # 1. 명확화 활성화 여부 확인
    configurable = Configuration.from_runnable_config(config)
    if not configurable.allow_clarification:
        return Command(goto="write_research_brief")
    
    # 2. 구조화된 출력 모델 준비
    clarification_model = (
        llm_model
        .with_structured_output(ClarifyWithUser)
        .with_retry(stop_after_attempt=configurable.max_structured_output_retries)
        .with_config(model_config)
    )
    
    # 3. 명확화 필요성 판단
    response = await clarification_model.ainvoke([HumanMessage(content=prompt_content)])
    
    # 4. 조건부 라우팅
    if response.need_clarification:
        return Command(goto=END, update={"messages": [AIMessage(content=response.question)]})
    else:
        return Command(goto="write_research_brief", update={"messages": [AIMessage(content=response.verification)]})
```

### 핵심 기술
- **구조화된 출력**: `with_structured_output(ClarifyWithUser)` - Pydantic 모델로 응답 파싱
- **동적 라우팅**: `Command(goto=...)` - 조건에 따라 다음 노드 결정
- **재시도 로직**: `with_retry()` - 구조화된 출력 실패 시 자동 재시도

## Phase 2: 연구 계획서 작성 (write_research_brief)

### 목적
사용자 메시지를 구조화된 연구 질문으로 변환합니다.

### 구현

```python
async def write_research_brief(state: AgentState, config: RunnableConfig) -> Command:
    # 1. 연구 모델 설정
    research_model = (
        llm_model.with_structured_output(ResearchQuestion)
        .with_retry(stop_after_attempt=configurable.max_structured_output_retries)
        .with_config(research_model_config)
    )
    
    # 2. 연구 계획서 생성
    response = await research_model.ainvoke([HumanMessage(content=prompt_content)])
    
    # 3. Supervisor 초기화
    return Command(
        goto="research_supervisor",
        update={
            "research_brief": response.research_brief,
            "supervisor_messages": {
                "type": "override",
                "value": [
                    SystemMessage(content=supervisor_system_prompt),
                    HumanMessage(content=response.research_brief),
                ],
            },
        },
    )
```

### 핵심 포인트
- 사용자 메시지를 상세한 연구 질문으로 확장
- Supervisor를 위한 시스템 프롬프트와 초기 메시지 설정
- `override_reducer`로 supervisor_messages 초기화

## Phase 3: 연구 수행 (Supervisor Subgraph)

### 3-1. supervisor 노드

```python
async def supervisor(state: SupervisorState, config: RunnableConfig) -> dict:
    # 도구 바인딩
    lead_researcher_tools = [ConductResearch, ResearchComplete, think_tool]
    research_model = llm_model.bind_tools(lead_researcher_tools)
    
    # 연구 전략 수립
    response = await research_model.ainvoke(supervisor_messages)
    
    return {
        "supervisor_messages": [response],
        "research_iterations": state.get("research_iterations", 0) + 1,
    }
```

**역할:**
- 연구 계획서 분석
- 연구 작업 분해 결정
- `ConductResearch` 도구로 작업 위임

### 3-2. supervisor_tools 노드

```python
async def supervisor_tools(state: SupervisorState, config: RunnableConfig) -> Command:
    # 1. 종료 조건 확인
    if exceeded_allowed_iterations or no_tool_calls or research_complete_tool_call:
        return Command(goto=END, update={...})
    
    # 2. think_tool 처리
    for tool_call in think_tool_calls:
        all_tool_messages.append(ToolMessage(...))
    
    # 3. ConductResearch 병렬 실행
    research_tasks = [
        researcher_subgraph.ainvoke({...}, config)
        for tool_call in allowed_conduct_research_calls
    ]
    tool_results = await asyncio.gather(*research_tasks)
    
    # 4. 결과 수집
    for observation, tool_call in zip(tool_results, allowed_conduct_research_calls):
        all_tool_messages.append(ToolMessage(content=observation.get("compressed_research")))
    
    return Command(goto="supervisor", update=update_payload)
```

**핵심 기능:**
- **병렬 실행**: 여러 Researcher를 동시에 실행
- **동시성 제한**: `max_concurrent_research_units`로 리소스 관리
- **결과 집계**: 모든 Researcher의 결과를 수집

## Phase 4: 개별 연구 (Researcher Subgraph)

### 4-1. researcher 노드

```python
async def researcher(state: ResearcherState, config: RunnableConfig) -> Command:
    # 1. 도구 로드
    tools = await get_all_tools(config)  # tavily_search, think_tool, MCP 도구
    
    # 2. 모델 바인딩
    research_model = llm_model.bind_tools(tools)
    
    # 3. 연구 수행
    messages = [SystemMessage(content=researcher_prompt)] + researcher_messages
    response = await research_model.ainvoke(messages)
    
    return Command(
        goto="researcher_tools",
        update={
            "researcher_messages": [response],
            "tool_call_iterations": state.get("tool_call_iterations", 0) + 1,
        },
    )
```

### 4-2. researcher_tools 노드

```python
async def researcher_tools(state: ResearcherState, config: RunnableConfig) -> Command:
    # 1. 도구 병렬 실행
    tool_execution_tasks = [
        execute_tool_safely(tools_by_name[tool_call["name"]], tool_call["args"], config)
        for tool_call in tool_calls
    ]
    observations = await asyncio.gather(*tool_execution_tasks)
    
    # 2. 종료 조건 확인
    if exceeded_iterations or research_complete_called:
        return Command(goto="compress_research", update={...})
    
    # 3. 연구 계속
    return Command(goto="researcher", update={"researcher_messages": tool_outputs})
```

**ReAct 패턴:**
```
researcher → researcher_tools → researcher → researcher_tools → ...
```

### 4-3. compress_research 노드

```python
async def compress_research(state: ResearcherState, config: RunnableConfig):
    while synthesis_attempts < max_attempts:
        try:
            response = await synthesizer_model.ainvoke(messages)
            return {
                "compressed_research": str(response.content),
                "raw_notes": [raw_notes_content]
            }
        except Exception as e:
            if is_token_limit_exceeded(e, model):
                researcher_messages = remove_up_to_last_ai_message(researcher_messages)
```

**기능:**
- 연구 결과 요약 및 정리
- 토큰 제한 초과 시 메시지 절단 후 재시도
- 원본 데이터와 압축 데이터 모두 반환

## Phase 5: 최종 보고서 생성 (final_report_generation)

```python
async def final_report_generation(state: AgentState, config: RunnableConfig):
    notes = state.get("notes", [])
    findings = "\n".join(notes)
    
    # 토큰 제한 재시도 로직
    while current_retry <= max_retries:
        try:
            final_report = await llm_model.with_config(writer_model_config).ainvoke([...])
            return {
                "final_report": final_report.content,
                "messages": [final_report],
                **cleared_state,
            }
        except Exception as e:
            if is_token_limit_exceeded(e, model):
                findings = findings[:findings_token_limit]
```

**기능:**
- 모든 연구 결과 종합
- 토큰 제한 초과 시 점진적 절단
- 상태 정리 (`cleared_state`)
